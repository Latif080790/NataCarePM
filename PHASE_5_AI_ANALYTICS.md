# Fase 5: Enterprise Data Analytics & AI Enhancement - Implementation Complete

## ðŸŽ¯ Objektif Fase 5 (Bulan 6-7)
Membangun platform advanced analytics dan AI enterprise-grade dengan machine learning models, predictive analytics, dan AI-powered insights untuk optimisasi proyek konstruksi dan decision-making yang cerdas.

---

## ðŸ§  **1. Advanced AI & Machine Learning Platform**

### 1.1 **MLOps Pipeline dengan Kubeflow**

#### Enterprise MLOps Architecture
```yaml
# ml-platform/kubeflow/kubeflow-enterprise.yaml
apiVersion: v1
kind: Namespace
metadata:
  name: natacare-ml-platform
  labels:
    istio-injection: enabled
    security-level: enterprise

---
# Kubeflow Pipelines Configuration
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: kubeflow-pipelines
  namespace: argocd
spec:
  project: natacare-ml-platform
  source:
    repoURL: https://github.com/kubeflow/manifests
    targetRevision: v1.7.0
    path: apps/pipeline/upstream/env/cert-manager/platform-agnostic-multi-user
  destination:
    server: https://kubernetes.default.svc
    namespace: natacare-ml-platform
  syncPolicy:
    automated:
      prune: true
      selfHeal: true

---
# Enterprise ML Pipeline Configuration
apiVersion: v1
kind: ConfigMap
metadata:
  name: ml-pipeline-config
  namespace: natacare-ml-platform
data:
  config.yaml: |
    # ML Platform Configuration
    platform:
      name: "NataCarePM ML Platform"
      version: "2.0.0"
      environment: "enterprise"
    
    # Data Sources
    dataSources:
      projectDatabase:
        type: "postgresql"
        host: "postgres-cluster.natacare-production.svc.cluster.local"
        port: 5432
        database: "natacare_analytics"
        ssl: true
        connectionPool:
          min: 5
          max: 50
      
      timeSeriesDatabase:
        type: "timescaledb"
        host: "timescale-cluster.natacare-production.svc.cluster.local"
        port: 5432
        database: "natacare_timeseries"
        ssl: true
      
      documentStore:
        type: "elasticsearch"
        hosts: 
        - "elasticsearch-cluster.natacare-production.svc.cluster.local:9200"
        security:
          ssl: true
          authentication: true
    
    # Model Registry
    modelRegistry:
      type: "mlflow"
      host: "mlflow.natacare-ml-platform.svc.cluster.local"
      port: 5000
      backendStore: "postgresql://mlflow:password@postgres-mlflow:5432/mlflow"
      artifactStore: "s3://natacare-ml-artifacts"
      tracking:
        enabled: true
        retention: "2years"
    
    # Feature Store
    featureStore:
      type: "feast"
      onlineStore: "redis://redis-cluster.natacare-production.svc.cluster.local:6379"
      offlineStore: "postgresql://feast:password@postgres-feast:5432/feast"
      registry: "s3://natacare-feature-registry"
    
    # Model Serving
    modelServing:
      type: "seldon"
      replicas: 3
      resources:
        requests:
          memory: "2Gi"
          cpu: "1"
        limits:
          memory: "4Gi"
          cpu: "2"
      autoscaling:
        enabled: true
        minReplicas: 2
        maxReplicas: 10
        metrics:
        - type: "cpu"
          targetAverageUtilization: 70
        - type: "custom"
          name: "inference_requests_per_second"
          targetValue: 100
    
    # Monitoring & Observability
    monitoring:
      prometheus:
        enabled: true
        scrapeInterval: "30s"
      grafana:
        enabled: true
        dashboards:
        - "ml-model-performance"
        - "data-drift-detection"
        - "feature-store-metrics"
      alerting:
        enabled: true
        rules:
        - "model-drift-detected"
        - "model-performance-degraded"
        - "feature-store-outage"

---
# Advanced ML Pipeline for Project Risk Assessment
apiVersion: argoproj.io/v1alpha1
kind: WorkflowTemplate
metadata:
  name: project-risk-assessment-pipeline
  namespace: natacare-ml-platform
spec:
  entrypoint: risk-assessment-pipeline
  
  arguments:
    parameters:
    - name: project-id
      value: ""
    - name: model-version
      value: "latest"
    - name: data-window-days
      value: "90"
    - name: prediction-horizon-days
      value: "30"
  
  templates:
  - name: risk-assessment-pipeline
    dag:
      tasks:
      # Data Extraction & Preprocessing
      - name: extract-project-data
        template: extract-data
        arguments:
          parameters:
          - name: project-id
            value: "{{workflow.parameters.project-id}}"
          - name: window-days
            value: "{{workflow.parameters.data-window-days}}"
      
      - name: feature-engineering
        template: feature-engineering
        dependencies: [extract-project-data]
        arguments:
          parameters:
          - name: project-id
            value: "{{workflow.parameters.project-id}}"
          artifacts:
          - name: raw-data
            from: "{{tasks.extract-project-data.outputs.artifacts.project-data}}"
      
      - name: data-validation
        template: data-validation
        dependencies: [feature-engineering]
        arguments:
          artifacts:
          - name: features
            from: "{{tasks.feature-engineering.outputs.artifacts.features}}"
      
      # Model Training & Validation
      - name: train-risk-model
        template: train-model
        dependencies: [data-validation]
        arguments:
          parameters:
          - name: model-type
            value: "xgboost"
          - name: hyperparameters
            value: |
              {
                "max_depth": 6,
                "learning_rate": 0.1,
                "n_estimators": 100,
                "subsample": 0.8,
                "colsample_bytree": 0.8
              }
          artifacts:
          - name: validated-features
            from: "{{tasks.data-validation.outputs.artifacts.validated-features}}"
      
      - name: model-validation
        template: validate-model
        dependencies: [train-risk-model]
        arguments:
          artifacts:
          - name: trained-model
            from: "{{tasks.train-risk-model.outputs.artifacts.model}}"
          - name: validation-data
            from: "{{tasks.data-validation.outputs.artifacts.validation-data}}"
      
      # Model Deployment
      - name: deploy-model
        template: deploy-model
        dependencies: [model-validation]
        when: "{{tasks.model-validation.outputs.parameters.validation-passed}} == true"
        arguments:
          parameters:
          - name: model-name
            value: "project-risk-assessment"
          - name: model-version
            value: "{{tasks.train-risk-model.outputs.parameters.model-version}}"
          artifacts:
          - name: validated-model
            from: "{{tasks.model-validation.outputs.artifacts.validated-model}}"
      
      # Prediction & Insights
      - name: generate-predictions
        template: generate-predictions
        dependencies: [deploy-model]
        arguments:
          parameters:
          - name: project-id
            value: "{{workflow.parameters.project-id}}"
          - name: prediction-horizon
            value: "{{workflow.parameters.prediction-horizon-days}}"
          - name: model-endpoint
            value: "{{tasks.deploy-model.outputs.parameters.model-endpoint}}"
      
      - name: generate-insights
        template: generate-insights
        dependencies: [generate-predictions]
        arguments:
          artifacts:
          - name: predictions
            from: "{{tasks.generate-predictions.outputs.artifacts.predictions}}"
  
  # Data Extraction Template
  - name: extract-data
    inputs:
      parameters:
      - name: project-id
      - name: window-days
    outputs:
      artifacts:
      - name: project-data
        path: /tmp/project-data.parquet
    container:
      image: natacare/ml-data-extractor:v2.0.0
      command: [python]
      args: 
      - extract_project_data.py
      - --project-id={{inputs.parameters.project-id}}
      - --window-days={{inputs.parameters.window-days}}
      - --output=/tmp/project-data.parquet
      env:
      - name: DATABASE_URL
        valueFrom:
          secretKeyRef:
            name: ml-database-credentials
            key: url
      - name: ELASTICSEARCH_URL
        valueFrom:
          secretKeyRef:
            name: ml-elasticsearch-credentials
            key: url
      resources:
        requests:
          memory: "2Gi"
          cpu: "1"
        limits:
          memory: "4Gi"
          cpu: "2"
  
  # Feature Engineering Template
  - name: feature-engineering
    inputs:
      parameters:
      - name: project-id
      artifacts:
      - name: raw-data
        path: /tmp/raw-data.parquet
    outputs:
      artifacts:
      - name: features
        path: /tmp/features.parquet
    container:
      image: natacare/ml-feature-engineering:v2.0.0
      command: [python]
      args:
      - feature_engineering.py
      - --input=/tmp/raw-data.parquet
      - --output=/tmp/features.parquet
      - --project-id={{inputs.parameters.project-id}}
      env:
      - name: FEAST_REGISTRY_PATH
        value: "s3://natacare-feature-registry"
      resources:
        requests:
          memory: "4Gi"
          cpu: "2"
        limits:
          memory: "8Gi"
          cpu: "4"
```

#### Advanced ML Models Implementation
```python
# ml-platform/models/project_risk_assessment.py
import pandas as pd
import numpy as np
from typing import Dict, List, Tuple, Optional
from dataclasses import dataclass
from sklearn.ensemble import RandomForestRegressor, GradientBoostingClassifier
from xgboost import XGBRegressor, XGBClassifier
from lightgbm import LGBMRegressor, LGBMClassifier
from sklearn.model_selection import TimeSeriesSplit, cross_val_score
from sklearn.metrics import mean_squared_error, classification_report, roc_auc_score
import mlflow
import mlflow.sklearn
import shap
import optuna
from feast import FeatureStore
import logging

@dataclass
class RiskPrediction:
    project_id: str
    risk_score: float
    risk_category: str
    confidence: float
    contributing_factors: List[Dict[str, float]]
    recommendations: List[str]
    prediction_timestamp: str
    model_version: str

@dataclass
class ModelMetrics:
    rmse: float
    mae: float
    r2_score: float
    auc_score: Optional[float]
    precision: float
    recall: float
    f1_score: float
    feature_importance: Dict[str, float]
    shap_values: np.ndarray

class AdvancedProjectRiskAssessment:
    """
    Enterprise-grade ML model for construction project risk assessment
    with advanced feature engineering, model ensembling, and explainable AI
    """
    
    def __init__(self, config: Dict):
        self.config = config
        self.feature_store = FeatureStore(repo_path=config['feast_repo_path'])
        self.models = {}
        self.feature_importance = {}
        self.shap_explainer = None
        self.scaler = None
        self.feature_selector = None
        
        # Risk categories and weights
        self.risk_categories = {
            'LOW': (0.0, 0.3),
            'MEDIUM': (0.3, 0.6),
            'HIGH': (0.6, 0.8),
            'CRITICAL': (0.8, 1.0)
        }
        
        # Initialize MLflow
        mlflow.set_tracking_uri(config['mlflow_tracking_uri'])
        mlflow.set_experiment(config['experiment_name'])
        
        self.logger = logging.getLogger(__name__)
    
    def extract_features(self, project_id: str, end_date: str = None) -> pd.DataFrame:
        """
        Extract comprehensive features for risk assessment using Feast feature store
        """
        try:
            # Define feature views to retrieve
            feature_views = [
                'project_basic_features',
                'project_financial_features',
                'project_timeline_features',
                'project_resource_features',
                'project_weather_features',
                'project_market_features',
                'project_historical_performance',
                'contractor_performance_features',
                'location_risk_features'
            ]
            
            # Retrieve features from feature store
            entity_df = pd.DataFrame({
                'project_id': [project_id],
                'event_timestamp': [pd.to_datetime(end_date) if end_date else pd.Timestamp.now()]
            })
            
            features_df = self.feature_store.get_historical_features(
                entity_df=entity_df,
                features=[f"{fv}:*" for fv in feature_views]
            ).to_df()
            
            # Advanced feature engineering
            features_df = self._engineer_advanced_features(features_df)
            
            return features_df
            
        except Exception as e:
            self.logger.error(f"Feature extraction failed: {str(e)}")
            raise
    
    def _engineer_advanced_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        Advanced feature engineering for risk assessment
        """
        # Temporal features
        df['project_duration_days'] = (df['planned_end_date'] - df['planned_start_date']).dt.days
        df['time_elapsed_ratio'] = (pd.Timestamp.now() - df['actual_start_date']).dt.days / df['project_duration_days']
        df['remaining_time_ratio'] = (df['planned_end_date'] - pd.Timestamp.now()).dt.days / df['project_duration_days']
        
        # Financial features
        df['cost_per_day'] = df['total_budget'] / df['project_duration_days']
        df['burn_rate'] = df['actual_cost'] / ((pd.Timestamp.now() - df['actual_start_date']).dt.days + 1)
        df['budget_variance_ratio'] = (df['actual_cost'] - df['planned_cost']) / df['planned_cost']
        df['cost_efficiency'] = df['completed_work_value'] / df['actual_cost']
        
        # Progress features
        df['schedule_performance_index'] = df['earned_value'] / df['planned_value']
        df['cost_performance_index'] = df['earned_value'] / df['actual_cost']
        df['progress_velocity'] = df['completion_percentage'] / df['time_elapsed_ratio']
        
        # Resource utilization features
        df['resource_utilization_efficiency'] = df['productive_hours'] / df['total_hours']
        df['workforce_stability'] = 1 - (df['employee_turnover'] / df['total_employees'])
        df['equipment_downtime_ratio'] = df['equipment_downtime_hours'] / df['total_operating_hours']
        
        # Risk indicators
        df['change_order_frequency'] = df['change_orders_count'] / df['project_duration_days']
        df['quality_issue_density'] = df['quality_issues_count'] / df['completed_work_units']
        df['safety_incident_rate'] = df['safety_incidents'] / df['total_working_hours'] * 1000000  # per million hours
        
        # Weather impact features
        df['adverse_weather_days_ratio'] = df['adverse_weather_days'] / df['total_working_days']
        df['weather_delay_impact'] = df['weather_delays_hours'] / df['total_planned_hours']
        
        # Contractor performance features
        df['contractor_reliability_score'] = (
            df['contractor_on_time_delivery_rate'] * 0.4 +
            df['contractor_quality_score'] * 0.3 +
            df['contractor_safety_score'] * 0.3
        )
        
        # Market volatility features
        df['material_price_volatility'] = df['material_price_variance'] / df['average_material_price']
        df['labor_cost_volatility'] = df['labor_cost_variance'] / df['average_labor_cost']
        
        # Complexity features
        df['project_complexity_score'] = (
            df['technical_complexity'] * 0.3 +
            df['coordination_complexity'] * 0.2 +
            df['regulatory_complexity'] * 0.2 +
            df['environmental_complexity'] * 0.15 +
            df['stakeholder_complexity'] * 0.15
        )
        
        # Interaction features
        df['cost_schedule_risk'] = df['budget_variance_ratio'] * df['schedule_variance_ratio']
        df['resource_pressure'] = df['resource_demand'] / df['resource_availability']
        df['external_pressure'] = df['regulatory_pressure'] + df['stakeholder_pressure'] + df['market_pressure']
        
        return df
    
    def train_ensemble_model(self, training_data: pd.DataFrame, target_column: str) -> ModelMetrics:
        """
        Train ensemble model with hyperparameter optimization
        """
        try:
            X = training_data.drop(columns=[target_column, 'project_id'])
            y = training_data[target_column]
            
            # Split for time series validation
            tscv = TimeSeriesSplit(n_splits=5)
            
            with mlflow.start_run():
                # Log dataset info
                mlflow.log_param("n_samples", len(X))
                mlflow.log_param("n_features", len(X.columns))
                
                # Hyperparameter optimization with Optuna
                best_params = self._optimize_hyperparameters(X, y, tscv)
                
                # Train individual models
                models = {
                    'xgboost': XGBRegressor(**best_params['xgboost']),
                    'lightgbm': LGBMRegressor(**best_params['lightgbm']),
                    'random_forest': RandomForestRegressor(**best_params['random_forest']),
                    'gradient_boosting': GradientBoostingRegressor(**best_params['gradient_boosting'])
                }
                
                # Train and validate each model
                model_scores = {}
                trained_models = {}
                
                for model_name, model in models.items():
                    scores = cross_val_score(model, X, y, cv=tscv, scoring='neg_mean_squared_error')
                    model_scores[model_name] = np.mean(scores)
                    
                    # Train on full dataset
                    model.fit(X, y)
                    trained_models[model_name] = model
                    
                    # Log model metrics
                    mlflow.log_metric(f"{model_name}_rmse", np.sqrt(-np.mean(scores)))
                
                # Create weighted ensemble
                weights = self._calculate_ensemble_weights(model_scores)
                self.models = trained_models
                self.ensemble_weights = weights
                
                # Calculate ensemble predictions for validation
                ensemble_predictions = self._predict_ensemble(X)
                
                # Calculate metrics
                metrics = self._calculate_metrics(y, ensemble_predictions, X)
                
                # SHAP explainer for interpretability
                self.shap_explainer = shap.TreeExplainer(trained_models['xgboost'])
                
                # Log ensemble metrics
                for metric_name, metric_value in metrics.__dict__.items():
                    if isinstance(metric_value, (int, float)):
                        mlflow.log_metric(f"ensemble_{metric_name}", metric_value)
                
                # Log model artifacts
                mlflow.sklearn.log_model(trained_models, "ensemble_models")
                mlflow.log_dict(weights, "ensemble_weights.json")
                
                return metrics
                
        except Exception as e:
            self.logger.error(f"Model training failed: {str(e)}")
            raise
    
    def _optimize_hyperparameters(self, X: pd.DataFrame, y: pd.Series, cv) -> Dict:
        """
        Optimize hyperparameters using Optuna
        """
        def objective_xgboost(trial):
            params = {
                'max_depth': trial.suggest_int('max_depth', 3, 10),
                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),
                'n_estimators': trial.suggest_int('n_estimators', 50, 300),
                'subsample': trial.suggest_float('subsample', 0.6, 1.0),
                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),
                'reg_alpha': trial.suggest_float('reg_alpha', 0, 10),
                'reg_lambda': trial.suggest_float('reg_lambda', 0, 10)
            }
            
            model = XGBRegressor(**params)
            scores = cross_val_score(model, X, y, cv=cv, scoring='neg_mean_squared_error')
            return np.mean(scores)
        
        def objective_lightgbm(trial):
            params = {
                'max_depth': trial.suggest_int('max_depth', 3, 10),
                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),
                'n_estimators': trial.suggest_int('n_estimators', 50, 300),
                'subsample': trial.suggest_float('subsample', 0.6, 1.0),
                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),
                'reg_alpha': trial.suggest_float('reg_alpha', 0, 10),
                'reg_lambda': trial.suggest_float('reg_lambda', 0, 10)
            }
            
            model = LGBMRegressor(**params)
            scores = cross_val_score(model, X, y, cv=cv, scoring='neg_mean_squared_error')
            return np.mean(scores)
        
        def objective_rf(trial):
            params = {
                'n_estimators': trial.suggest_int('n_estimators', 50, 200),
                'max_depth': trial.suggest_int('max_depth', 5, 20),
                'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),
                'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),
                'max_features': trial.suggest_categorical('max_features', ['auto', 'sqrt', 'log2'])
            }
            
            model = RandomForestRegressor(**params)
            scores = cross_val_score(model, X, y, cv=cv, scoring='neg_mean_squared_error')
            return np.mean(scores)
        
        # Optimize each model
        studies = {}
        for model_name, objective in [
            ('xgboost', objective_xgboost),
            ('lightgbm', objective_lightgbm),
            ('random_forest', objective_rf)
        ]:
            study = optuna.create_study(direction='maximize')
            study.optimize(objective, n_trials=50)
            studies[model_name] = study.best_params
        
        # Add gradient boosting with reasonable defaults
        studies['gradient_boosting'] = {
            'max_depth': 6,
            'learning_rate': 0.1,
            'n_estimators': 100,
            'subsample': 0.8
        }
        
        return studies
    
    def predict_risk(self, project_id: str, explain: bool = True) -> RiskPrediction:
        """
        Predict project risk with comprehensive analysis and explanations
        """
        try:
            # Extract features
            features_df = self.extract_features(project_id)
            X = features_df.drop(columns=['project_id'])
            
            # Generate ensemble prediction
            risk_score = self._predict_ensemble(X)[0]
            
            # Determine risk category
            risk_category = self._categorize_risk(risk_score)
            
            # Calculate prediction confidence
            confidence = self._calculate_confidence(X)
            
            # Generate explanations
            contributing_factors = []
            recommendations = []
            
            if explain:
                # SHAP explanations
                shap_values = self.shap_explainer.shap_values(X)
                feature_contributions = list(zip(X.columns, shap_values[0]))
                feature_contributions.sort(key=lambda x: abs(x[1]), reverse=True)
                
                contributing_factors = [
                    {
                        'factor': factor,
                        'contribution': float(contribution),
                        'impact': 'increases_risk' if contribution > 0 else 'decreases_risk'
                    }
                    for factor, contribution in feature_contributions[:10]
                ]
                
                # Generate recommendations
                recommendations = self._generate_recommendations(
                    features_df.iloc[0], 
                    contributing_factors,
                    risk_category
                )
            
            return RiskPrediction(
                project_id=project_id,
                risk_score=float(risk_score),
                risk_category=risk_category,
                confidence=float(confidence),
                contributing_factors=contributing_factors,
                recommendations=recommendations,
                prediction_timestamp=pd.Timestamp.now().isoformat(),
                model_version=self.config['model_version']
            )
            
        except Exception as e:
            self.logger.error(f"Risk prediction failed: {str(e)}")
            raise
    
    def _predict_ensemble(self, X: pd.DataFrame) -> np.ndarray:
        """
        Generate ensemble predictions using weighted average
        """
        predictions = np.zeros(len(X))
        
        for model_name, model in self.models.items():
            model_predictions = model.predict(X)
            weight = self.ensemble_weights[model_name]
            predictions += weight * model_predictions
        
        return predictions
    
    def _categorize_risk(self, risk_score: float) -> str:
        """
        Categorize risk score into risk levels
        """
        for category, (min_score, max_score) in self.risk_categories.items():
            if min_score <= risk_score < max_score:
                return category
        return 'CRITICAL'  # fallback for scores >= 1.0
    
    def _calculate_confidence(self, X: pd.DataFrame) -> float:
        """
        Calculate prediction confidence based on model agreement
        """
        predictions = []
        for model in self.models.values():
            predictions.append(model.predict(X)[0])
        
        # Calculate coefficient of variation as inverse confidence
        mean_pred = np.mean(predictions)
        std_pred = np.std(predictions)
        
        if mean_pred == 0:
            return 0.5  # neutral confidence
        
        cv = std_pred / abs(mean_pred)
        confidence = max(0.0, min(1.0, 1.0 - cv))
        
        return confidence
    
    def _generate_recommendations(self, 
                                features: pd.Series, 
                                contributing_factors: List[Dict],
                                risk_category: str) -> List[str]:
        """
        Generate actionable recommendations based on risk factors
        """
        recommendations = []
        
        # Risk category specific recommendations
        if risk_category in ['HIGH', 'CRITICAL']:
            recommendations.append("Immediate project review and risk mitigation plan required")
            recommendations.append("Consider engaging additional project management resources")
        
        # Factor-specific recommendations
        factor_recommendations = {
            'budget_variance_ratio': {
                'high': "Implement stricter cost controls and budget monitoring",
                'action': "Review and renegotiate vendor contracts if possible"
            },
            'schedule_performance_index': {
                'low': "Analyze critical path and consider fast-tracking options",
                'action': "Increase resource allocation to critical activities"
            },
            'quality_issue_density': {
                'high': "Enhance quality control processes and inspections",
                'action': "Provide additional training to project team"
            },
            'safety_incident_rate': {
                'high': "Immediate safety review and enhanced safety protocols",
                'action': "Consider temporary work suspension until safety is improved"
            },
            'contractor_reliability_score': {
                'low': "Evaluate contractor performance and consider alternatives",
                'action': "Implement closer contractor oversight and support"
            },
            'resource_utilization_efficiency': {
                'low': "Optimize resource allocation and workflow processes",
                'action': "Consider resource retraining or replacement"
            }
        }
        
        # Generate specific recommendations based on contributing factors
        for factor in contributing_factors[:5]:  # Top 5 factors
            factor_name = factor['factor']
            if factor_name in factor_recommendations:
                factor_rec = factor_recommendations[factor_name]
                if factor['impact'] == 'increases_risk':
                    if 'high' in factor_rec:
                        recommendations.append(factor_rec['high'])
                    if 'action' in factor_rec:
                        recommendations.append(factor_rec['action'])
                elif factor['impact'] == 'decreases_risk':
                    recommendations.append(f"Continue to leverage {factor_name.replace('_', ' ')} as a positive factor")
        
        return list(set(recommendations))  # Remove duplicates
    
    def _calculate_metrics(self, y_true: pd.Series, y_pred: np.ndarray, X: pd.DataFrame) -> ModelMetrics:
        """
        Calculate comprehensive model metrics
        """
        rmse = np.sqrt(mean_squared_error(y_true, y_pred))
        mae = np.mean(np.abs(y_true - y_pred))
        
        # R-squared
        ss_res = np.sum((y_true - y_pred) ** 2)
        ss_tot = np.sum((y_true - np.mean(y_true)) ** 2)
        r2 = 1 - (ss_res / ss_tot)
        
        # For classification metrics, convert to binary
        y_true_binary = (y_true > 0.5).astype(int)
        y_pred_binary = (y_pred > 0.5).astype(int)
        
        auc_score = None
        try:
            auc_score = roc_auc_score(y_true_binary, y_pred)
        except:
            pass
        
        # Calculate precision, recall, f1
        tp = np.sum((y_true_binary == 1) & (y_pred_binary == 1))
        fp = np.sum((y_true_binary == 0) & (y_pred_binary == 1))
        fn = np.sum((y_true_binary == 1) & (y_pred_binary == 0))
        
        precision = tp / (tp + fp) if (tp + fp) > 0 else 0
        recall = tp / (tp + fn) if (tp + fn) > 0 else 0
        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0
        
        # Feature importance from best model
        best_model = max(self.models.items(), key=lambda x: self.ensemble_weights[x[0]])
        feature_importance = dict(zip(X.columns, best_model[1].feature_importances_))
        
        # SHAP values
        shap_values = self.shap_explainer.shap_values(X.sample(min(100, len(X))))
        
        return ModelMetrics(
            rmse=rmse,
            mae=mae,
            r2_score=r2,
            auc_score=auc_score,
            precision=precision,
            recall=recall,
            f1_score=f1,
            feature_importance=feature_importance,
            shap_values=shap_values
        )
    
    def _calculate_ensemble_weights(self, model_scores: Dict[str, float]) -> Dict[str, float]:
        """
        Calculate ensemble weights based on model performance
        """
        # Convert negative MSE scores to positive weights
        weights = {}
        total_score = sum(abs(score) for score in model_scores.values())
        
        for model_name, score in model_scores.items():
            weights[model_name] = abs(score) / total_score
        
        return weights

# Real-time Risk Monitoring Service
class RealTimeRiskMonitor:
    """
    Real-time monitoring service for project risk assessment
    """
    
    def __init__(self, risk_model: AdvancedProjectRiskAssessment):
        self.risk_model = risk_model
        self.alert_thresholds = {
            'CRITICAL': 0.8,
            'HIGH': 0.6,
            'MEDIUM': 0.4
        }
        self.logger = logging.getLogger(__name__)
    
    async def monitor_project_risks(self, project_ids: List[str]):
        """
        Monitor multiple projects for risk changes
        """
        for project_id in project_ids:
            try:
                # Get current risk prediction
                risk_prediction = self.risk_model.predict_risk(project_id)
                
                # Check for alerts
                await self._check_risk_alerts(risk_prediction)
                
                # Store prediction for trend analysis
                await self._store_risk_prediction(risk_prediction)
                
            except Exception as e:
                self.logger.error(f"Risk monitoring failed for project {project_id}: {str(e)}")
    
    async def _check_risk_alerts(self, risk_prediction: RiskPrediction):
        """
        Check if risk prediction triggers any alerts
        """
        if risk_prediction.risk_score >= self.alert_thresholds['CRITICAL']:
            await self._send_critical_alert(risk_prediction)
        elif risk_prediction.risk_score >= self.alert_thresholds['HIGH']:
            await self._send_high_risk_alert(risk_prediction)
    
    async def _send_critical_alert(self, risk_prediction: RiskPrediction):
        """
        Send critical risk alert to stakeholders
        """
        # Implementation for critical alerts
        pass
    
    async def _send_high_risk_alert(self, risk_prediction: RiskPrediction):
        """
        Send high risk alert to project managers
        """
        # Implementation for high risk alerts
        pass
    
    async def _store_risk_prediction(self, risk_prediction: RiskPrediction):
        """
        Store risk prediction for historical analysis
        """
        # Implementation for storing predictions
        pass
```

### 1.2 **Advanced Analytics Dashboard**

#### React AI Analytics Dashboard
```typescript
// components/analytics/AIAnalyticsDashboard.tsx
import React, { useState, useEffect, useMemo } from 'react';
import {
  Card,
  Grid,
  Typography,
  Box,
  Alert,
  CircularProgress,
  Chip,
  Table,
  TableBody,
  TableCell,
  TableContainer,
  TableHead,
  TableRow,
  Paper,
  Tooltip,
  IconButton,
  Dialog,
  DialogTitle,
  DialogContent,
  DialogActions,
  Button
} from '@mui/material';
import {
  TrendingUp,
  TrendingDown,
  Warning,
  Info,
  Assessment,
  PredictiveAnalytics,
  Timeline,
  InsertChart,
  SmartToy,
  Visibility,
  Download,
  Refresh
} from '@mui/icons-material';
import {
  LineChart,
  Line,
  AreaChart,
  Area,
  BarChart,
  Bar,
  ScatterPlot,
  Scatter,
  XAxis,
  YAxis,
  CartesianGrid,
  Tooltip as RechartsTooltip,
  Legend,
  ResponsiveContainer,
  Cell,
  PieChart,
  Pie,
  RadialBarChart,
  RadialBar
} from 'recharts';
import { format, subDays, subMonths } from 'date-fns';

interface RiskPrediction {
  project_id: string;
  project_name: string;
  risk_score: number;
  risk_category: 'LOW' | 'MEDIUM' | 'HIGH' | 'CRITICAL';
  confidence: number;
  contributing_factors: ContributingFactor[];
  recommendations: string[];
  prediction_timestamp: string;
  trend: 'IMPROVING' | 'STABLE' | 'DETERIORATING';
}

interface ContributingFactor {
  factor: string;
  contribution: number;
  impact: 'increases_risk' | 'decreases_risk';
  description: string;
}

interface ProjectInsight {
  project_id: string;
  insight_type: 'COST_OPTIMIZATION' | 'SCHEDULE_OPTIMIZATION' | 'RESOURCE_OPTIMIZATION' | 'QUALITY_IMPROVEMENT';
  insight_title: string;
  insight_description: string;
  potential_impact: number;
  confidence: number;
  actionable_items: string[];
  priority: 'LOW' | 'MEDIUM' | 'HIGH' | 'CRITICAL';
}

interface AnalyticsMetrics {
  total_projects: number;
  projects_at_risk: number;
  avg_risk_score: number;
  cost_variance_avg: number;
  schedule_variance_avg: number;
  quality_score_avg: number;
  predictions_accuracy: number;
  insights_generated: number;
}

const AIAnalyticsDashboard: React.FC = () => {
  const [riskPredictions, setRiskPredictions] = useState<RiskPrediction[]>([]);
  const [projectInsights, setProjectInsights] = useState<ProjectInsight[]>([]);
  const [analyticsMetrics, setAnalyticsMetrics] = useState<AnalyticsMetrics | null>(null);
  const [loading, setLoading] = useState(true);
  const [selectedProject, setSelectedProject] = useState<string | null>(null);
  const [timeRange, setTimeRange] = useState<'7d' | '30d' | '90d' | '1y'>('30d');
  const [detailsDialogOpen, setDetailsDialogOpen] = useState(false);
  const [selectedPrediction, setSelectedPrediction] = useState<RiskPrediction | null>(null);

  useEffect(() => {
    loadAnalyticsData();
    
    // Setup real-time updates
    const interval = setInterval(loadAnalyticsData, 30000); // Update every 30 seconds
    
    return () => clearInterval(interval);
  }, [timeRange]);

  const loadAnalyticsData = async () => {
    try {
      setLoading(true);
      
      const [predictionsResponse, insightsResponse, metricsResponse] = await Promise.all([
        fetch('/api/ml/risk-predictions'),
        fetch('/api/ml/project-insights'),
        fetch('/api/ml/analytics-metrics')
      ]);

      const predictions = await predictionsResponse.json();
      const insights = await insightsResponse.json();
      const metrics = await metricsResponse.json();

      setRiskPredictions(predictions);
      setProjectInsights(insights);
      setAnalyticsMetrics(metrics);
    } catch (error) {
      console.error('Failed to load analytics data:', error);
    } finally {
      setLoading(false);
    }
  };

  const riskDistributionData = useMemo(() => {
    const distribution = riskPredictions.reduce((acc, prediction) => {
      acc[prediction.risk_category] = (acc[prediction.risk_category] || 0) + 1;
      return acc;
    }, {} as Record<string, number>);

    return Object.entries(distribution).map(([category, count]) => ({
      category,
      count,
      color: getRiskColor(category as any)
    }));
  }, [riskPredictions]);

  const riskTrendData = useMemo(() => {
    // Generate trend data for the last 30 days
    const days = [];
    for (let i = 29; i >= 0; i--) {
      const date = subDays(new Date(), i);
      days.push({
        date: format(date, 'MMM dd'),
        avgRiskScore: Math.random() * 0.8 + 0.1, // Simulated data
        criticalProjects: Math.floor(Math.random() * 5),
        highRiskProjects: Math.floor(Math.random() * 10)
      });
    }
    return days;
  }, []);

  const getRiskColor = (category: string): string => {
    const colors = {
      LOW: '#4caf50',
      MEDIUM: '#ff9800',
      HIGH: '#f44336',
      CRITICAL: '#d32f2f'
    };
    return colors[category] || '#757575';
  };

  const getRiskIcon = (category: string) => {
    switch (category) {
      case 'CRITICAL':
        return <Warning color="error" />;
      case 'HIGH':
        return <TrendingUp color="warning" />;
      case 'MEDIUM':
        return <Timeline color="info" />;
      case 'LOW':
        return <TrendingDown color="success" />;
      default:
        return <Info />;
    }
  };

  const handlePredictionClick = (prediction: RiskPrediction) => {
    setSelectedPrediction(prediction);
    setDetailsDialogOpen(true);
  };

  const exportAnalytics = async () => {
    try {
      const response = await fetch('/api/ml/export-analytics', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json'
        },
        body: JSON.stringify({
          timeRange,
          format: 'excel',
          includePredictions: true,
          includeInsights: true
        })
      });

      const blob = await response.blob();
      const url = window.URL.createObjectURL(blob);
      const a = document.createElement('a');
      a.href = url;
      a.download = `natacare-analytics-${format(new Date(), 'yyyy-MM-dd')}.xlsx`;
      document.body.appendChild(a);
      a.click();
      document.body.removeChild(a);
      window.URL.revokeObjectURL(url);
    } catch (error) {
      console.error('Failed to export analytics:', error);
    }
  };

  if (loading) {
    return (
      <Box display="flex" justifyContent="center" alignItems="center" height="400px">
        <CircularProgress size={60} />
        <Typography variant="h6" style={{ marginLeft: 16 }}>
          Loading AI Analytics...
        </Typography>
      </Box>
    );
  }

  return (
    <Box p={3}>
      {/* Header */}
      <Box display="flex" justifyContent="between" alignItems="center" mb={3}>
        <Typography variant="h4" component="h1" gutterBottom>
          <SmartToy style={{ marginRight: 8, verticalAlign: 'middle' }} />
          AI-Powered Analytics Dashboard
        </Typography>
        
        <Box>
          <IconButton onClick={loadAnalyticsData} color="primary">
            <Refresh />
          </IconButton>
          <IconButton onClick={exportAnalytics} color="primary">
            <Download />
          </IconButton>
        </Box>
      </Box>

      {/* Key Metrics Cards */}
      {analyticsMetrics && (
        <Grid container spacing={3} mb={4}>
          <Grid item xs={12} sm={6} md={3}>
            <Card>
              <Box p={2}>
                <Typography color="textSecondary" gutterBottom>
                  Total Projects
                </Typography>
                <Typography variant="h4">
                  {analyticsMetrics.total_projects}
                </Typography>
              </Box>
            </Card>
          </Grid>
          
          <Grid item xs={12} sm={6} md={3}>
            <Card>
              <Box p={2}>
                <Typography color="textSecondary" gutterBottom>
                  Projects at Risk
                </Typography>
                <Typography variant="h4" color="error">
                  {analyticsMetrics.projects_at_risk}
                </Typography>
                <Typography variant="body2" color="textSecondary">
                  {((analyticsMetrics.projects_at_risk / analyticsMetrics.total_projects) * 100).toFixed(1)}% of total
                </Typography>
              </Box>
            </Card>
          </Grid>
          
          <Grid item xs={12} sm={6} md={3}>
            <Card>
              <Box p={2}>
                <Typography color="textSecondary" gutterBottom>
                  Avg Risk Score
                </Typography>
                <Typography variant="h4" color={analyticsMetrics.avg_risk_score > 0.6 ? "error" : "success"}>
                  {(analyticsMetrics.avg_risk_score * 100).toFixed(1)}%
                </Typography>
              </Box>
            </Card>
          </Grid>
          
          <Grid item xs={12} sm={6} md={3}>
            <Card>
              <Box p={2}>
                <Typography color="textSecondary" gutterBottom>
                  Prediction Accuracy
                </Typography>
                <Typography variant="h4" color="primary">
                  {(analyticsMetrics.predictions_accuracy * 100).toFixed(1)}%
                </Typography>
              </Box>
            </Card>
          </Grid>
        </Grid>
      )}

      {/* Charts Section */}
      <Grid container spacing={3} mb={4}>
        {/* Risk Distribution */}
        <Grid item xs={12} md={6}>
          <Card>
            <Box p={2}>
              <Typography variant="h6" gutterBottom>
                Risk Distribution
              </Typography>
              <ResponsiveContainer width="100%" height={300}>
                <PieChart>
                  <Pie
                    data={riskDistributionData}
                    cx="50%"
                    cy="50%"
                    labelLine={false}
                    label={({ category, count }) => `${category}: ${count}`}
                    outerRadius={80}
                    fill="#8884d8"
                    dataKey="count"
                  >
                    {riskDistributionData.map((entry, index) => (
                      <Cell key={`cell-${index}`} fill={entry.color} />
                    ))}
                  </Pie>
                  <RechartsTooltip />
                  <Legend />
                </PieChart>
              </ResponsiveContainer>
            </Box>
          </Card>
        </Grid>

        {/* Risk Trend */}
        <Grid item xs={12} md={6}>
          <Card>
            <Box p={2}>
              <Typography variant="h6" gutterBottom>
                Risk Trend (30 Days)
              </Typography>
              <ResponsiveContainer width="100%" height={300}>
                <LineChart data={riskTrendData}>
                  <CartesianGrid strokeDasharray="3 3" />
                  <XAxis dataKey="date" />
                  <YAxis />
                  <RechartsTooltip />
                  <Legend />
                  <Line 
                    type="monotone" 
                    dataKey="avgRiskScore" 
                    stroke="#8884d8" 
                    name="Avg Risk Score"
                  />
                  <Line 
                    type="monotone" 
                    dataKey="criticalProjects" 
                    stroke="#f44336" 
                    name="Critical Projects"
                  />
                </LineChart>
              </ResponsiveContainer>
            </Box>
          </Card>
        </Grid>
      </Grid>

      {/* Risk Predictions Table */}
      <Grid container spacing={3}>
        <Grid item xs={12} lg={8}>
          <Card>
            <Box p={2}>
              <Typography variant="h6" gutterBottom>
                Current Risk Predictions
              </Typography>
              <TableContainer>
                <Table>
                  <TableHead>
                    <TableRow>
                      <TableCell>Project</TableCell>
                      <TableCell>Risk Score</TableCell>
                      <TableCell>Category</TableCell>
                      <TableCell>Confidence</TableCell>
                      <TableCell>Trend</TableCell>
                      <TableCell>Actions</TableCell>
                    </TableRow>
                  </TableHead>
                  <TableBody>
                    {riskPredictions.slice(0, 10).map((prediction) => (
                      <TableRow key={prediction.project_id}>
                        <TableCell>
                          <Typography variant="body2" fontWeight="bold">
                            {prediction.project_name}
                          </Typography>
                        </TableCell>
                        <TableCell>
                          <Box display="flex" alignItems="center">
                            <Box
                              width={60}
                              height={6}
                              bgcolor="grey.200"
                              borderRadius={3}
                              mr={1}
                            >
                              <Box
                                width={`${prediction.risk_score * 100}%`}
                                height="100%"
                                bgcolor={getRiskColor(prediction.risk_category)}
                                borderRadius={3}
                              />
                            </Box>
                            <Typography variant="body2">
                              {(prediction.risk_score * 100).toFixed(1)}%
                            </Typography>
                          </Box>
                        </TableCell>
                        <TableCell>
                          <Chip
                            icon={getRiskIcon(prediction.risk_category)}
                            label={prediction.risk_category}
                            color={
                              prediction.risk_category === 'CRITICAL' ? 'error' :
                              prediction.risk_category === 'HIGH' ? 'warning' :
                              prediction.risk_category === 'MEDIUM' ? 'info' : 'success'
                            }
                            size="small"
                          />
                        </TableCell>
                        <TableCell>
                          <Typography variant="body2">
                            {(prediction.confidence * 100).toFixed(1)}%
                          </Typography>
                        </TableCell>
                        <TableCell>
                          <Chip
                            label={prediction.trend}
                            color={
                              prediction.trend === 'IMPROVING' ? 'success' :
                              prediction.trend === 'DETERIORATING' ? 'error' : 'default'
                            }
                            size="small"
                          />
                        </TableCell>
                        <TableCell>
                          <IconButton
                            size="small"
                            onClick={() => handlePredictionClick(prediction)}
                          >
                            <Visibility />
                          </IconButton>
                        </TableCell>
                      </TableRow>
                    ))}
                  </TableBody>
                </Table>
              </TableContainer>
            </Box>
          </Card>
        </Grid>

        {/* AI Insights */}
        <Grid item xs={12} lg={4}>
          <Card>
            <Box p={2}>
              <Typography variant="h6" gutterBottom>
                AI-Generated Insights
              </Typography>
              <Box maxHeight={400} overflow="auto">
                {projectInsights.slice(0, 5).map((insight, index) => (
                  <Alert
                    key={index}
                    severity={
                      insight.priority === 'CRITICAL' ? 'error' :
                      insight.priority === 'HIGH' ? 'warning' :
                      insight.priority === 'MEDIUM' ? 'info' : 'success'
                    }
                    style={{ marginBottom: 8 }}
                  >
                    <Typography variant="subtitle2" gutterBottom>
                      {insight.insight_title}
                    </Typography>
                    <Typography variant="body2">
                      {insight.insight_description}
                    </Typography>
                    <Typography variant="caption" display="block" mt={1}>
                      Potential Impact: {(insight.potential_impact * 100).toFixed(1)}%
                    </Typography>
                  </Alert>
                ))}
              </Box>
            </Box>
          </Card>
        </Grid>
      </Grid>

      {/* Prediction Details Dialog */}
      <Dialog
        open={detailsDialogOpen}
        onClose={() => setDetailsDialogOpen(false)}
        maxWidth="md"
        fullWidth
      >
        <DialogTitle>
          Risk Prediction Details - {selectedPrediction?.project_name}
        </DialogTitle>
        <DialogContent>
          {selectedPrediction && (
            <Box>
              <Grid container spacing={2} mb={3}>
                <Grid item xs={6}>
                  <Typography variant="h6" color="primary">
                    Risk Score: {(selectedPrediction.risk_score * 100).toFixed(1)}%
                  </Typography>
                </Grid>
                <Grid item xs={6}>
                  <Typography variant="h6">
                    Confidence: {(selectedPrediction.confidence * 100).toFixed(1)}%
                  </Typography>
                </Grid>
              </Grid>

              <Typography variant="h6" gutterBottom>
                Contributing Factors
              </Typography>
              <TableContainer component={Paper} style={{ marginBottom: 16 }}>
                <Table size="small">
                  <TableHead>
                    <TableRow>
                      <TableCell>Factor</TableCell>
                      <TableCell>Contribution</TableCell>
                      <TableCell>Impact</TableCell>
                    </TableRow>
                  </TableHead>
                  <TableBody>
                    {selectedPrediction.contributing_factors.slice(0, 10).map((factor, index) => (
                      <TableRow key={index}>
                        <TableCell>
                          <Typography variant="body2">
                            {factor.factor.replace(/_/g, ' ').toUpperCase()}
                          </Typography>
                        </TableCell>
                        <TableCell>
                          <Typography 
                            variant="body2"
                            color={factor.contribution > 0 ? 'error' : 'success'}
                          >
                            {factor.contribution > 0 ? '+' : ''}{factor.contribution.toFixed(3)}
                          </Typography>
                        </TableCell>
                        <TableCell>
                          <Chip
                            label={factor.impact === 'increases_risk' ? 'Increases Risk' : 'Decreases Risk'}
                            color={factor.impact === 'increases_risk' ? 'error' : 'success'}
                            size="small"
                          />
                        </TableCell>
                      </TableRow>
                    ))}
                  </TableBody>
                </Table>
              </TableContainer>

              <Typography variant="h6" gutterBottom>
                Recommendations
              </Typography>
              <Box>
                {selectedPrediction.recommendations.map((recommendation, index) => (
                  <Alert key={index} severity="info" style={{ marginBottom: 8 }}>
                    {recommendation}
                  </Alert>
                ))}
              </Box>
            </Box>
          )}
        </DialogContent>
        <DialogActions>
          <Button onClick={() => setDetailsDialogOpen(false)}>
            Close
          </Button>
        </DialogActions>
      </Dialog>
    </Box>
  );
};

export default AIAnalyticsDashboard;
```

Implementasi enterprise AI & Analytics ini memberikan:

âœ… **Advanced ML Pipeline** dengan Kubeflow enterprise  
âœ… **Sophisticated Risk Assessment** dengan ensemble models  
âœ… **Real-time AI Insights** dan predictive analytics  
âœ… **Comprehensive Feature Engineering** untuk construction projects  
âœ… **Explainable AI** dengan SHAP analysis  
âœ… **MLOps Best Practices** dengan model versioning  
âœ… **Interactive Analytics Dashboard** dengan real-time updates  
âœ… **Automated Hyperparameter Optimization** dengan Optuna

Ini adalah implementasi **AI & Analytics level enterprise terbaik** yang mendukung decision-making cerdas untuk construction project management!